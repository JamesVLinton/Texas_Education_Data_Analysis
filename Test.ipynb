{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    port=int(3306),\n",
    "    user=\"root\",\n",
    "    passwd='vaughn',\n",
    "    db=\"Texas_Education_Data\",\n",
    "    charset='utf8mb4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_df(df, window=4):\n",
    "    main_rolling_df = pd.DataFrame(columns=df.columns)\n",
    "    for district in df.District_Id.unique():\n",
    "        district_df = df[df.District_Id == district]\n",
    "        \n",
    "        rolling_df = district_df.rolling(window).mean()\n",
    "        rolling_df['Year'] = district_df['Year'].rolling(window).max()\n",
    "\n",
    "        main_rolling_df = pd.concat([main_rolling_df, rolling_df])\n",
    "\n",
    "    main_rolling_df = main_rolling_df.dropna(how='all')\n",
    "    return main_rolling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximate district affluence by dividing local revenue by number of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select e.District_Id, e.Year, e.Fall_Enrollment, r.Total_Local_Revenue_All_Funds as Local_Revenue, r.Total_State_Revenue_All_Funds as State_Revenue from Enrollment e, Revenue r where e.District_Id = r.District_Id and e.Year = r.Year\"\n",
    "affluence_df = pd.read_sql_query(query,conn)\n",
    "\n",
    "affluence_df = affluence_df.set_index(['District_Id', 'Year']).dropna()\n",
    "\n",
    "affluence_df['Local_Per_Student'] = affluence_df['Local_Revenue'] / affluence_df['Fall_Enrollment']\n",
    "affluence_df['State_Per_Student'] = affluence_df['State_Revenue'] / affluence_df['Fall_Enrollment']\n",
    "\n",
    "affluence_df = affluence_df.loc[affluence_df['Local_Revenue'] > 0].loc[affluence_df['Fall_Enrollment'] > 0]\n",
    "affluence_df = affluence_df.loc[affluence_df['State_Revenue'] > 0].loc[affluence_df['Fall_Enrollment'] > 0]\n",
    "\n",
    "# rolling_affluence_df = get_rolling_df(affluence_df.reset_index()).set_index(['District_Id','Year'])\n",
    "# rolling_affluence_df\n",
    "# affluence_df['Local_Per_Student'], affluence_bins = pd.qcut(affluence_df['Local_Per_Student'], 50, labels=False, retbins=True, duplicates='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get class teacher salary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select District_Id, Year, Num_Employees, Total_Employee_Pay from Teachers\"\n",
    "salary_df = pd.read_sql_query(query,conn)\n",
    "salary_df = salary_df.groupby(['District_Id','Year']).sum()\n",
    "# salary_df['Avg_Salary'] = salary_df['Total_Employee_Pay'] / salary_df['Num_Employees']\n",
    "# rolling_salary_df = get_rolling_df(salary_df.reset_index()).set_index(['District_Id','Year'])\n",
    "# rolling_salary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get exponential weighted average of test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from Test_Scores\"\n",
    "test_scores_df = pd.read_sql_query(query,conn).set_index(['District_Id', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_average_scores = pd.DataFrame(columns=test_scores_df.columns).set_index(['District_Id','Year'])\n",
    "# for district in test_scores_df.District_Id.unique():\n",
    "#     district_df = test_scores_df[test_scores_df.District_Id == district].set_index(['District_Id','Year'])\n",
    "#     rolling_df = district_df.ewm(span=20, adjust=False).mean()\n",
    "    \n",
    "#     rolling_average_scores = pd.concat([rolling_average_scores, rolling_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break % above critical ratio sat or act in quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sat_act_crit_rate = rolling_average_scores['Above_Crit_Rate_Sat_Act'].dropna().reset_index()\n",
    "# sat_act_crit_rate = sat_act_crit_rate.loc[sat_act_crit_rate.Year > 2007].set_index(['District_Id','Year'])\n",
    "# test_score_quartiles,bins = pd.qcut(sat_act_crit_rate['Above_Crit_Rate_Sat_Act'], 4, labels=False, retbins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get class size data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select District_Id, Year, Num_Teachers, Num_Students from Classes\"\n",
    "class_size_df = pd.read_sql_query(query,conn)\n",
    "class_size_df = class_size_df.groupby(['District_Id', 'Year']).sum()\n",
    "class_size_df['Class_Size'] = class_size_df['Num_Students'] / class_size_df['Num_Teachers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get expenditures by function with 4 year simple moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from Functions\"\n",
    "functions_df = pd.read_sql_query(query,conn).set_index(['District_Id', 'Year'])\n",
    "# rolling_functions_df = get_rolling_df(functions_df).set_index(['District_Id','Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from Enrollment\"\n",
    "enrollment_df = pd.read_sql_query(query,conn).set_index(['District_Id', 'Year'])\n",
    "funct_per_student = pd.concat([functions_df, enrollment_df], axis=1)\n",
    "funct_per_student = funct_per_student.div(funct_per_student['Fall_Enrollment'],axis=0).drop(['Fall_Enrollment'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert $ to % of all funds budget and add critical ratio to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rolling_functions_df = rolling_functions_df.filter(regex='.*_General_Funds$')\n",
    "# func_all_funds_percent = pd.concat([rolling_functions_df, rolling_affluence_df, test_score_quartiles],axis=1).dropna().rename(columns={'Above_Crit_Rate_Sat_Act':'target'})\n",
    "# func_all_funds_percent\n",
    "# pd.concat([functions_df, class_size_df, test_scores_df, salary_df, affluence_df], axis=1)\n",
    "dataset = pd.concat([funct_per_student, test_scores_df['Avg_Act'].to_frame()], axis=1).reset_index()\n",
    "dataset = dataset[dataset.Year > 2004]\n",
    "\n",
    "#remove districts without data between 2005-2019\n",
    "for dist in dataset.District_Id.unique():\n",
    "    if len(dataset[dataset.District_Id == dist].Year.unique()) != len(range(2005,2020)):\n",
    "        dataset = dataset[dataset.District_Id != dist]\n",
    "\n",
    "#remove district with less than 60% of act scores reported\n",
    "for dist in dataset.District_Id.unique():\n",
    "    dist_df = dataset[dataset.District_Id == dist]\n",
    "    tot_rows = dist_df.shape[0]\n",
    "    act_rows = dist_df[dist_df.Avg_Act.notna()].shape[0]\n",
    "    if act_rows / tot_rows < .6:\n",
    "        dataset = dataset[dataset.District_Id != dist]\n",
    "\n",
    "#interpolate missing values\n",
    "for dist in dataset.District_Id.unique():\n",
    "    dist_df = dataset[dataset.District_Id == dist]\n",
    "    dataset[dataset.District_Id == dist] = dist_df.interpolate(limit_direction='both')\n",
    "\n",
    "dataset = dataset.filter(regex='(.*_General_Funds$)|(Avg_Act)|(District_Id)|(Year)')\n",
    "\n",
    "# dataset[['Avg_Act','Total_Expenditure_By_Function_General_Funds']].plot.scatter(x='Total_Expenditure_By_Function_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Instruction_General_Funds']].plot.scatter(x='Instruction_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Security_Monitoring_General_Funds']].plot.scatter(x='Security_Monitoring_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Food_General_Funds']].plot.scatter(x='Food_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Community_Services_General_Funds']].plot.scatter(x='Community_Services_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Guidance_Counseling_Services_General_Funds']].plot.scatter(x='Guidance_Counseling_Services_General_Funds',y='Avg_Act')\n",
    "# dataset[['Avg_Act','Curriculum_Staff_Develop_General_Funds']].plot.scatter(x='Curriculum_Staff_Develop_General_Funds',y='Avg_Act')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_windows(df, window_size=4):\n",
    "    inputs = np.empty((0, window_size, len(dataset.columns)))\n",
    "    labels = np.array([])\n",
    "    t = 0\n",
    "    for i in range(len(df.Year.unique()) - window_size + 1):\n",
    "        start_year = 2005\n",
    "        \n",
    "        window = df.loc[df.Year >= start_year + i].loc[df.Year < start_year + i + window_size]\n",
    "        ids = len(window.District_Id.unique())\n",
    "        window = np.array(window)\n",
    "        \n",
    "        window_inputs = np.array(np.array_split(window, ids))\n",
    "        window_labels = window_inputs[:,-1,-1].copy()\n",
    "        window_inputs[:,-1,-1] = 1\n",
    "        \n",
    "        inputs = np.concatenate((inputs, window_inputs),axis=0)\n",
    "        \n",
    "        labels = np.append(labels,[window_labels])\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "label_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_labels = label_scaler.fit_transform(np.array(dataset)[:,-1].reshape(-1,1))\n",
    "\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = feature_scaler.fit_transform(np.array(dataset)[:,2:-1])\n",
    "\n",
    "scaled_dataset = pd.DataFrame(np.hstack((np.array(dataset)[:,:2], scaled_features, scaled_labels)), columns=dataset.columns)\n",
    "\n",
    "window = 4\n",
    "inputs, labels = split_windows(scaled_dataset, window)\n",
    "\n",
    "def interleave_windows(data, window):\n",
    "    empty = np.empty((data.shape))\n",
    "    s = int(data.shape[0] / window)\n",
    "    \n",
    "    for i in range(window):\n",
    "        a = inputs[i*s:(i+1)*s]\n",
    "        empty[i::window] = a\n",
    "    \n",
    "    return empty\n",
    "\n",
    "inputs = interleave_windows(inputs,window)\n",
    "\n",
    "X = np.array([i.mean(axis=0) for i in inputs])\n",
    "y, bins = pd.qcut(labels, 4, labels=False, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4180253623188406\n",
      "[[285 147  69  64]\n",
      " [127 195 145  88]\n",
      " [ 77 154 164 133]\n",
      " [ 50  87 144 279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.52       565\n",
      "           1       0.33      0.35      0.34       555\n",
      "           2       0.31      0.31      0.31       528\n",
      "           3       0.49      0.50      0.50       560\n",
      "\n",
      "    accuracy                           0.42      2208\n",
      "   macro avg       0.42      0.42      0.42      2208\n",
      "weighted avg       0.42      0.42      0.42      2208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,shuffle=False)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100, bootstrap=True)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = (np.array([.6,1]) * inputs.shape[0]).astype(int) \n",
    "\n",
    "train_inputs = inputs[:splits[0],:,:]\n",
    "test_inputs = inputs[splits[0]:splits[1],:,:]\n",
    "\n",
    "train_labels = labels[:splits[0]]\n",
    "test_labels = labels[splits[0]:splits[1]]\n",
    "\n",
    "train_inputs = train_inputs[:,:,2:]#.reshape(train_inputs.shape[0],8,1)\n",
    "test_inputs = test_inputs[:,:,2:]#.reshape(test_inputs.shape[0],8,1)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).shuffle(buffer_size=1024).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_labels)).shuffle(buffer_size=1024).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9b27e129e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9b27e129e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "207/207 [==============================] - 1s 5ms/step - loss: 0.0158 - mean_absolute_error: 0.0957\n",
      "Epoch 2/5\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0829\n",
      "Epoch 3/5\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0827\n",
      "Epoch 4/5\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0814\n",
      "Epoch 5/5\n",
      "207/207 [==============================] - 1s 5ms/step - loss: 0.0106 - mean_absolute_error: 0.0809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b27e21e50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units = 64, return_sequences = True, input_shape = (4, 18)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(units = 64, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(tf.keras.layers.LSTM(units = 64, return_sequences = True))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(units = 64, return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(), loss = tf.losses.MeanSquaredError(), metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "# model.fit(train_dataset, epochs = 5)\n",
    "model.fit(np.random.rand(train_inputs.shape[0],train_inputs.shape[1],train_inputs.shape[2]),train_labels, epochs = 5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9b285f6170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9b285f6170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1566528520153083"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_inputs)\n",
    "predictions = label_scaler.inverse_transform(predictions)\n",
    "actual = label_scaler.inverse_transform(test_labels.reshape(1,-1))\n",
    "np.sqrt(np.mean((predictions - actual)**2))\n",
    "# list(np.hstack((actual.T, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(actual, range(actual), label = \"line 1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
